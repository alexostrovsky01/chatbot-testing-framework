# configs/test_config.yaml

# -------------------------
# General Settings
# -------------------------
dataset_path: "tests/data/test_questions.csv"
results_dir: "tests/results"

# -------------------------
# Phase 1: Message Sending
# -------------------------
# Configure the client to call our local Flask app.
client:
  type: "api"
  delay: 3  # Delay between requests to avoid overwhelming the server
  settings:
    url: "http://127.0.0.1:5002/invoke"
    method: "POST"
    headers:
      "Content-Type": "application/json"
    body_template: '{ "question": "{question}", "session_id": "{session_id}", "trace_config": {trace_config} }'

# -------------------------
# Tracing & Data Storage
# -------------------------
# The framework will look for traces in a local file.
# The mock_chatbot_app.py is configured to write to this same file.
tracing:
  recorder:
    type: "local_json"
    settings:
      filepath: "tests/results/traces_v2.json"
# tracing:
#   recorder:
#     type: "dynamodb"
#     settings:
#       table_name: "chatbot-traces"
#       region: "us-east-1"
#       run_id_key: "run_id"

# ------------------------------------
# Phase 2 & 3: Evaluation & Latency
# ------------------------------------
evaluation:
  prompts_path: "tests/configs/prompts_v2.py"
  workflow_description: >
    A multi-step HR support chatbot. It answers questions related to the HR Code of Conduct, Expense Policy, IT Onboarding, Payrol, Performance Reviews, and vacation Policy. 

  # Configure the LLM evaluator to use Google Gemini.
  llm_provider:
    type: "openai"
    requests_delay: 10  # Delay between requests to avoid rate limits                                                                                    
    settings:                                                                                                 
      model: "gpt-4.1"
